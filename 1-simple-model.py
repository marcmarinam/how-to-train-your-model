#  python -m pip install pandas xgboost matplotlib scikit-learn joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    confusion_matrix,
    roc_curve,
    precision_recall_curve,
    average_precision_score,
)
import matplotlib.pyplot as plt
import joblib

# === CONFIGURATION ===
CSV_PATH = "training_data.csv"
TARGET_COLUMN = "label_3"
RANDOM_SEED = 42
SAVE_METRICS_TO = "run_metrics.json"
SHAP_SAMPLE_SIZE = 1000
EXPERIMENT_NAME = "hint_lover_xgb"

print("üîç Loading and preprocessing data...")
# === LOAD AND CLEAN DATA ===
df = pd.read_csv(CSV_PATH)
df.columns = [col.lower() for col in df.columns]
df.fillna(0, inplace=True)

# Split features and labels
NON_FEATURE_COLUMNS = [
    "event_id",
    "user_id",
    "derived_tstamp",
    "has_managed_hint_next_1_days",
    "has_managed_hint_next_3_days",
    "has_managed_hint_next_7_days",
    "label_1",
    "label_3",
    "label_7",
]
feature_columns = [
    col
    for col in df.columns
    if col not in NON_FEATURE_COLUMNS and df[col].dtype != "object"
]

X = df[feature_columns]
y = df[TARGET_COLUMN]

print(f"‚úÖ Loaded {len(df)} rows with {len(feature_columns)} features")

# === SPLIT INTO TRAIN/VAL/TEST ===
print("üìä Splitting data into train/validation/test sets...")
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=RANDOM_SEED, stratify=y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=y_temp
)

print(f"üìÅ Training set: {len(X_train)} rows")
print(f"üìÅ Validation set: {len(X_val)} rows")
print(f"üìÅ Test set: {len(X_test)} rows")


# === TRAIN MODEL ===
print("üöÄ Training XGBoost model...")
model = XGBClassifier(
    n_estimators=200,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=RANDOM_SEED,
    eval_metric="logloss",
    use_label_encoder=False,
    objective="binary:logistic",
)
model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=10)
print("‚úÖ Model training complete.")

print("üìà Evaluating model on validation set...")
y_pred = model.predict(X_val)
y_prob = model.predict_proba(X_val)[:, 1]

roc_auc = roc_auc_score(y_val, y_prob)
cm = confusion_matrix(y_val, y_pred).tolist()
cr = classification_report(y_val, y_pred, output_dict=True)

# Log metrics
print("roc_auc", roc_auc)
print("confusion_matrix", cm)
print("classification_report", cr)
print("f1_class_0", cr["0"]["f1-score"])
print("f1_class_1", cr["1"]["f1-score"])
print("accuracy", cr["accuracy"])

# Save confusion matrix as artifact
plt.figure()
plt.imshow(confusion_matrix(y_val, y_pred), cmap="Blues")
plt.title("Confusion Matrix")
plt.colorbar()
plt.tight_layout()
plt.savefig("confusion_matrix.png")

# Save and log model
model_path = "hint_lover_model.pkl"
joblib.dump(model, model_path)


# Log feature importances
fig, ax = plt.subplots()
ax.hist(model.feature_importances_, bins=50)
ax.axvline(0.002, color="green", linestyle="--", label="0.002")
ax.axvline(0.005, color="red", linestyle="--", label="0.005")
ax.set_title("Feature Importance Distribution")
ax.set_xlabel("Importance Score")
ax.set_ylabel("Feature Count")
ax.legend()
fig.tight_layout()
fig.savefig("feature_importance.png")

# Save ROC Curve
fpr, tpr, _ = roc_curve(y_val, y_prob)
plt.figure()
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve")
plt.grid()
plt.tight_layout()
plt.savefig("roc_curve.png")

# Save PR Curve
precision, recall, _ = precision_recall_curve(y_val, y_prob)
ap_score = average_precision_score(y_val, y_prob)
plt.figure()
plt.plot(recall, precision, label=f"AP = {ap_score:.3f}")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.grid()
plt.tight_layout()
plt.savefig("pr_curve.png")
